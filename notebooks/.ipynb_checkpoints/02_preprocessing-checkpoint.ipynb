{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "69ab53a0-0450-4c67-af76-9c720a47f587",
   "metadata": {},
   "source": [
    "# Traffic Sign Recognition – Data Preprocessing\n",
    "\n",
    "In this notebook, we prepare the dataset for training a neural network.\n",
    "This includes splitting the data and encoding the labels.\n",
    "The goal is to prepare the data for training a Convolutional Neural Network (CNN).\n",
    "\n",
    "We cover the following steps:\n",
    "1. Loading preprocessed data\n",
    "2. Train–test split\n",
    "3. Image resizing\n",
    "4. Normalize pixel values\n",
    "5. Convert labels to categorical (one-hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c9e3289a-b4de-49a3-8949-a465ec23095e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd638c94-be10-4363-b6e2-b4568de65b98",
   "metadata": {},
   "source": [
    "### Step 1: Load dataset (simulated)\n",
    "\n",
    "In a real project, we would load the traffic sign images and labels here.  \n",
    "Since this is a training/demo notebook, we'll simulate a small dataset to show the preprocessing workflow.\n",
    "\n",
    "Each image is represented as a 3D array (height, width, channels), and labels are integers representing classes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "95991c72-ff3e-4f98-a35b-57d4a187f826",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simulated dataset. Number of images: 50\n",
      "Number of labels: 50\n",
      "Example image shape: (37, 28, 3)\n",
      "Example label: 2\n"
     ]
    }
   ],
   "source": [
    "# Simulate 50 RGB images of varying sizes and random labels (0-9 classes)\n",
    "num_samples = 50\n",
    "images = [np.random.randint(0, 256, size=(np.random.randint(28, 40), np.random.randint(28, 40), 3), dtype=np.uint8)\n",
    "          for _ in range(num_samples)]\n",
    "labels = np.random.randint(0, 10, size=(num_samples,))\n",
    "\n",
    "print(\"Simulated dataset. Number of images:\", len(images))\n",
    "print(\"Number of labels:\", len(labels))\n",
    "print(\"Example image shape:\", images[0].shape)\n",
    "print(\"Example label:\", labels[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "504af1d5-1fad-41d3-92b7-5f586d7f3334",
   "metadata": {},
   "source": [
    "## Step 2: Train–test split\n",
    "\n",
    "Before training a CNN, we split the dataset:\n",
    "\n",
    "- **Training set**: Used to teach the model.\n",
    "- **Test set**: Used to evaluate the model on unseen data.\n",
    "\n",
    "**Important:** Some traffic sign classes have very few images (1 image).  \n",
    "`train_test_split` with `stratify` requires **at least 2 images per class**.  \n",
    "We will remove these rare classes for this demo.\n",
    "\n",
    "- Our filtered dataset has **29 classes** but only **88 images**.\n",
    "- To perform a stratified split, the test set must have **at least 1 sample per class**.\n",
    "- We'll increase `test_size` to 0.35 (~31 images) to satisfy this condition.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "63bd4c6c-c5db-491a-9d4f-fc1692df818e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using test_size = 0.33 to satisfy stratification constraints\n",
      "Training set size: 59\n",
      "Test set size: 29\n"
     ]
    }
   ],
   "source": [
    "num_classes = len(set(labels_filtered))\n",
    "test_size = max(0.2, num_classes / len(labels_filtered))  # ensure >= 1 per class\n",
    "\n",
    "print(f\"Using test_size = {test_size:.2f} to satisfy stratification constraints\")\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    images_filtered,\n",
    "    labels_filtered,\n",
    "    test_size=test_size,\n",
    "    random_state=42,\n",
    "    stratify=labels_filtered\n",
    ")\n",
    "\n",
    "print(\"Training set size:\", len(X_train))\n",
    "print(\"Test set size:\", len(X_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f457227f-0156-40a4-bc21-09934768246b",
   "metadata": {},
   "source": [
    "#### Notes\n",
    "\n",
    "1. `test_size` is automatically increased if the number of classes is high relative to dataset size.\n",
    "2. Stratified split ensures each class appears in both train and test sets.\n",
    "3. This prevents `ValueError` due to too few samples in some classes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09e5be40-b26f-4b09-9d1f-d5ad2e6d33a6",
   "metadata": {},
   "source": [
    "### Step 3: Image resizing\n",
    "\n",
    "CNNs require all input images to have the same size.  \n",
    "Traffic sign images come in different shapes, so we need to resize them to a fixed size (e.g., 32x32 pixels) for consistency.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fee0ae69-4f5f-44b7-b492-847ba5611033",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training images resized shape: (59, 32, 32, 3)\n",
      "Test images resized shape: (29, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "# Resize all images to 32x32\n",
    "X_train_resized = np.array([cv2.resize(img, (32, 32)) for img in X_train])\n",
    "X_test_resized = np.array([cv2.resize(img, (32, 32)) for img in X_test])\n",
    "\n",
    "print(\"Training images resized shape:\", X_train_resized.shape)\n",
    "print(\"Test images resized shape:\", X_test_resized.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ead30cd3-e539-4cfd-bf83-6c37810c3fc0",
   "metadata": {},
   "source": [
    "### Step 4: Normalize pixel values\n",
    "\n",
    "Neural networks train more efficiently when input values are scaled.  \n",
    "We convert pixel values from the range [0, 255] to [0, 1].\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "07ab7103-cc2c-426e-97c2-6e675ab2fdf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pixel values normalized. Min: 5.0322659173041016e-08 Max: 0.003921505220453935\n"
     ]
    }
   ],
   "source": [
    "X_train_norm = X_train_resized / 255.0\n",
    "X_test_norm = X_test_resized / 255.0\n",
    "\n",
    "print(\"Pixel values normalized. Min:\", X_train_norm.min(), \"Max:\", X_train_norm.max())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daf8be5b-c9a3-4837-943d-83a798fdb9a5",
   "metadata": {},
   "source": [
    "### Step 5: Convert labels to categorical (one-hot)\n",
    "\n",
    "CNNs output probabilities for each class, so labels need to be one-hot encoded.  \n",
    "Example: class 3 → [0, 0, 0, 1, 0, ...]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "387c683c-65fd-479b-bbb3-e325a2d0731a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape labels to 2D\n",
    "y_train_reshaped = np.array(y_train).reshape(-1, 1)\n",
    "y_test_reshaped = np.array(y_test).reshape(-1, 1)\n",
    "\n",
    "encoder = OneHotEncoder(sparse_output=False)\n",
    "\n",
    "# Fit on training labels and transform both train and test\n",
    "y_train_cat = encoder.fit_transform(y_train_reshaped)\n",
    "y_test_cat = encoder.transform(y_test_reshaped)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dafaacf7-3d7d-484e-a0d8-0c6047ffa1d3",
   "metadata": {},
   "source": [
    "### Step 6: Save preprocessed data\n",
    "\n",
    "We save the normalized images and one-hot labels to `.npy` files.  \n",
    "This allows us to quickly load preprocessed data in future notebooks without repeating all preprocessing steps.\n",
    "In a real project, after resizing and normalizing, we would save the preprocessed images and labels \n",
    "to disk for faster loading in later steps.  \n",
    "\n",
    "Since this notebook is for demonstration, we'll simulate the save process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ea7497d4-c80a-405d-b40a-ca85d8255587",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessed images would be saved to 'assets/images_preprocessed.npy'\n",
      "Preprocessed labels would be saved to 'assets/labels_preprocessed.npy'\n"
     ]
    }
   ],
   "source": [
    "# Normally, you would do:\n",
    "# np.save(\"assets/images_preprocessed.npy\", X_train_norm)\n",
    "# np.save(\"assets/labels_preprocessed.npy\", y_train_cat)\n",
    "\n",
    "# Here, just print a message to show what would happen\n",
    "print(\"Preprocessed images would be saved to 'assets/images_preprocessed.npy'\")\n",
    "print(\"Preprocessed labels would be saved to 'assets/labels_preprocessed.npy'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfe0b026-ae91-4248-8753-3b3c6078eb3f",
   "metadata": {},
   "source": [
    "Saving preprocessed data avoids repeating time-consuming steps like resizing and normalization.\n",
    "\n",
    "In a real dataset, you would replace the print statements with np.save to write actual .npy files.\n",
    "\n",
    "This keeps the notebook lightweight for training/demo purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7c6749e-8915-4e45-a875-0fb5b4b4323b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
