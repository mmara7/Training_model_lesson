{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "de10a455-c24f-4724-862e-90570947d755",
   "metadata": {},
   "source": [
    "# Traffic Sign Recognition – Model Training Walkthrough\n",
    "\n",
    "In this notebook, we simulate training a CNN on traffic sign images.  \n",
    "Since this is a **demo for learning purposes**, we'll use **random data** to demonstrate the workflow, without installing Tensorflow\n",
    "\n",
    "We will cover:\n",
    "- Model definition (CNN layers explained)\n",
    "- Model compilation\n",
    "- Simulated training (`fit`)\n",
    "- Basic evaluation with predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48624c8e-b8ac-4dbc-91e0-fda8e3609d48",
   "metadata": {},
   "source": [
    "# What does training a model mean?\n",
    "\n",
    "Training a Convolutional Neural Network (CNN) involves:\n",
    "\n",
    "1. Showing the network input images (X_train) with their correct labels (y_train).  \n",
    "2. The CNN learns patterns (like edges, shapes, colors) in the images.  \n",
    "3. During training, the model adjusts its internal parameters (weights) to minimize errors in prediction.  \n",
    "4. After enough training, the CNN should generalize well to **unseen images** (X_test) and predict their classes correctly.  \n",
    "\n",
    "> In this demo, we simulate this process using random images and predictions.\n",
    "\n",
    "## Step 1 - Imports & Simulated Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a1be9f56-61fa-4fc0-8cf6-a60a8ec2379b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1 – Imports & simulated dataset\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Simulate a small dataset\n",
    "num_samples = 100\n",
    "img_height, img_width, channels = 32, 32, 3\n",
    "num_classes = 5  # small number for demo\n",
    "\n",
    "# Random images and labels\n",
    "X_train = np.random.rand(num_samples, img_height, img_width, channels)\n",
    "y_train = np.random.randint(0, num_classes, size=(num_samples,))\n",
    "\n",
    "X_test = np.random.rand(20, img_height, img_width, channels)\n",
    "y_test = np.random.randint(0, num_classes, size=(20,))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b138f931-8d63-4255-bd90-3d1c82bb02da",
   "metadata": {},
   "source": [
    "### Notes on the dataset\n",
    "- `X_train` and `X_test` are arrays of images (simulated as random numbers here).\n",
    "- `y_train` and `y_test` are labels for each image (random integers representing classes).\n",
    "- In a real project, these would be your preprocessed traffic sign images.\n",
    "- We use these to **simulate CNN training** without actually running TensorFlow.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "943ff4a2-e150-4703-893c-14d4eae7750b",
   "metadata": {},
   "source": [
    "## Step 2 – Simulated CNN Training\n",
    "A CNN typically has multiple layers:  \n",
    "1. **Convolutional layers** – extract local patterns (edges, shapes).  \n",
    "2. **Pooling layers** – reduce spatial dimensions, keeping essential features.  \n",
    "3. **Flatten layer** – convert 2D feature maps into a 1D vector.  \n",
    "4. **Dense (fully connected) layers** – combine features for classification.  \n",
    "\n",
    "Here, we simulate training by generating random weights and performing a \"forward pass\".\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d54f7728-9c47-478c-88ee-bcc2645d8c5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simulated predictions (first 5): [0 0 0 0 0]\n",
      "True labels (first 5): [4 4 1 3 2]\n"
     ]
    }
   ],
   "source": [
    "# Each \"layer\" produces a transformation (simplified)\n",
    "def simulated_layer(x, output_units):\n",
    "    # Flatten input\n",
    "    x_flat = x.reshape(x.shape[0], -1)  # shape (num_samples, img_height*img_width*channels)\n",
    "    input_units = x_flat.shape[1]       # 3072 for 32x32x3\n",
    "    weights = np.random.rand(input_units, output_units)\n",
    "    bias = np.random.rand(output_units)\n",
    "    return np.dot(x_flat, weights) + bias\n",
    "\n",
    "# Simulated forward pass\n",
    "layer1 = simulated_layer(X_train, 32)       # hidden layer\n",
    "layer2 = simulated_layer(layer1, num_classes)  # output layer\n",
    "\n",
    "# Softmax to get probabilities\n",
    "def softmax(x):\n",
    "    e_x = np.exp(x - np.max(x, axis=1, keepdims=True))\n",
    "    return e_x / e_x.sum(axis=1, keepdims=True)\n",
    "\n",
    "y_train_pred_prob = softmax(layer2)\n",
    "y_train_pred = np.argmax(y_train_pred_prob, axis=1)\n",
    "\n",
    "print(\"Simulated predictions (first 5):\", y_train_pred[:5])\n",
    "print(\"True labels (first 5):\", y_train[:5])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bc0e20e-9db2-4d5a-adf1-a17fe8987a75",
   "metadata": {},
   "source": [
    "- `layer1` simulates the hidden layer after convolution + pooling + flatten.  \n",
    "- `layer2` simulates the dense output layer.  \n",
    "- `softmax` converts the final outputs into probabilities for each class.  \n",
    "- `y_train_pred` are the predicted classes.  \n",
    "- This is a **simplified demonstration**, not real training.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cfb8d19-7a84-4130-a96a-105e09a7c020",
   "metadata": {},
   "source": [
    "## Step 3 - Key Takeaways\n",
    "- In real CNN training, weights are **learned from data** using backpropagation and gradient descent.  \n",
    "- Convolutional layers detect local patterns, pooling reduces data size, dense layers classify features.  \n",
    "- Softmax outputs probabilities, allowing for multi-class classification.  \n",
    "- Even in a simplified simulation, this structure shows the flow of data from input → hidden → output.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a913bf76-ba82-4a3d-a975-72ef1f529810",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
